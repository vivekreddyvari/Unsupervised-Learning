{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Negative Matrix factorization\n",
    "- NMF = 'non-negative matrix factorization' \n",
    "\n",
    "#### Like PCA, NMF is a dimension reduction technique\n",
    "- Easy to understand\n",
    "- can be applied to any data-set\n",
    "- however, all feature samples must be non-negative (>=0)\n",
    "\n",
    "#### Interpretable parts\n",
    "- NMF expresses documents as combinations of topics (or 'themes')\n",
    "- NMF expresses images as combinations of patterns\n",
    "\n",
    "#### NMF in SciKit Learn\n",
    "- follows same fit(), transform() pattern\n",
    "- the desired number of components must always be specified(n_components=2)\n",
    "- works with numpy arrays and wit csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example word-frequency array\n",
    "# - each row is document\n",
    "# - each column is word\n",
    "# - measures presence of words in each document\n",
    "# tf is the frequency of words in the documents\n",
    "# idf is the inverse document frequency of words in the document\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=2)\n",
    "model.fit(samples)\n",
    "nmf_features=model.transform(samples)\n",
    "\n",
    "# NMF has components\n",
    "print(model.components_)\n",
    "\n",
    "# entries in the nmf components are always non-negative\n",
    "\n",
    "# NMF features\n",
    "print(nmf_features)\n",
    "\n",
    "# NMF components and NMF features can be combined to re-construct the original data of dataset\n",
    "\n",
    "# Reconstruction of a sample\n",
    "print(sample[i,:])\n",
    "print(nmf_features[i,:])\n",
    "\n",
    "# mulitplying components by features values, and add up\n",
    "# can be used for product of matrices\n",
    "\n",
    "# NMF only works with non-negative data, only\n",
    "# - such as word frequencies\n",
    "# - images encoded as arrays\n",
    "# - audio spectrums\n",
    "# - Purchase historys of ecommerice websites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF applied to Wikipedia articles\n",
    "\n",
    "In the video, you saw NMF applied to transform a toy word-frequency array. Now it's your turn to apply NMF, this time using the tf-idf word-frequency array of Wikipedia articles, given as a csr matrix articles. Here, fit the model and transform the articles. In the next exercise, you'll explore the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Create an NMF instance: model\n",
    "model = NMF(n_components=6)\n",
    "\n",
    "# Fit the model to articles\n",
    "model.fit(articles)\n",
    "\n",
    "# Transform the articles: nmf_features\n",
    "nmf_features = model.transform(articles)\n",
    "\n",
    "# Print the NMF features\n",
    "print(nmf_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF features of the Wikipedia articles\n",
    "\n",
    "Now you will explore the NMF features you created in the previous exercise. A solution to the previous exercise has been pre-loaded, so the array nmf_features is available. Also available is a list titles giving the title of each Wikipedia article.\n",
    "\n",
    "When investigating the features, notice that for both actors, the NMF feature 3 has by far the highest value. This means that both articles are reconstructed using mainly the 3rd NMF component. In the next video, you'll see why: NMF components represent topics (for instance, acting!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a pandas DataFrame: df\n",
    "df = pd.DataFrame(nmf_features, index=titles)\n",
    "\n",
    "# Print the row for 'Anne Hathaway'\n",
    "print(df.loc['Anne Hathaway'])\n",
    "\n",
    "# Print the row for 'Denzel Washington'\n",
    "print(df.loc['Denzel Washington'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMF Learns interpretable parts\n",
    "- Word articles - word-frequency array articles (td-idf)\n",
    "- 20,000 scientific articles(rows)\n",
    "- 800 words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(article.shape)\n",
    "\n",
    "# Import NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# tokenize\n",
    "nmf = NMF(n_components=0)\n",
    "\n",
    "# fit\n",
    "nmf.fit(articles)\n",
    "\n",
    "# print components\n",
    "print(nmf.components_.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMF components\n",
    "\n",
    "#### For documents:\n",
    "- NMF components represent topics\n",
    "- NMF features combine topics into documents\n",
    "\n",
    "#### For images\n",
    "- NMF components are parts of images\n",
    "\n",
    "#### Gray Scale Images\n",
    "- \"Grayscale\" image = no colors, only shades of gray\n",
    "- Measure pixel brightness\n",
    "- Represent with value 0 and 1 (0 is black)\n",
    "- image can be represent as two-dimensional array of elements \n",
    "\n",
    "#### Grayscale images as flat array\n",
    "- Enumerate the entries\n",
    "- Row-by-Row\n",
    "- From left to right\n",
    "\n",
    "#### Encode a collection of images\n",
    "- Collections of images of the same size\n",
    "- Encode a 2D array\n",
    "- Each row corresponds to an image\n",
    "- Each columns corresponds to an pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples\n",
    "print(sample)\n",
    "\n",
    "# bitmap - encoding\n",
    "bitmap = sample.reshape((2,3))\n",
    "\n",
    "# Return 2d-array\n",
    "print(bitmap)\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotting \n",
    "plt.imshow(bitmap, cmap='gray', interploation='nearest')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF learns topics of documents\n",
    "\n",
    "In the video, you learned when NMF is applied to documents, the components correspond to topics of documents, and the NMF features reconstruct the documents from the topics. Verify this for yourself for the NMF model that you built earlier using the Wikipedia articles. Previously, you saw that the 3rd NMF feature value was high for the articles about actors Anne Hathaway and Denzel Washington. In this exercise, identify the topic of the corresponding NMF component.\n",
    "\n",
    "The NMF model you built earlier is available as model, while words is a list of the words that label the columns of the word-frequency array.\n",
    "\n",
    "After you are done, take a moment to recognise the topic that the articles about Anne Hathaway and Denzel Washington have in common!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame: components_df\n",
    "components_df = pd.DataFrame(model.components_, columns=words)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(components_df.shape)\n",
    "\n",
    "# Select row 3: component\n",
    "component = components_df.iloc[3]\n",
    "\n",
    "# Print result of nlargest\n",
    "print(component.nlargest())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the LED digits dataset\n",
    "\n",
    "In the following exercises, you'll use NMF to decompose grayscale images into their commonly occurring patterns. Firstly, explore the image dataset and see how it is encoded as an array. You are given 100 images as a 2D array samples, where each row represents a single 13x8 image. The images in your dataset are pictures of a LED digital display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Select the 0th row: digit\n",
    "digit = samples[0]\n",
    "\n",
    "# Print digit\n",
    "print(digit)\n",
    "\n",
    "# Reshape digit to a 13x8 array: bitmap\n",
    "bitmap = digit.reshape((13,8))\n",
    "\n",
    "# Print bitmap\n",
    "print(bitmap)\n",
    "\n",
    "# Use plt.imshow to display bitmap\n",
    "plt.imshow(bitmap, cmap='gray', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF learns the parts of images\n",
    "\n",
    "Now use what you've learned about NMF to decompose the digits dataset. You are again given the digit images as a 2D array samples. This time, you are also provided with a function show_as_image() that displays the image encoded by any 1D array:\n",
    "\n",
    "def show_as_image(sample):\n",
    "    bitmap = sample.reshape((13, 8))\n",
    "    plt.figure()\n",
    "    plt.imshow(bitmap, cmap='gray', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "After you are done, take a moment to look through the plots and notice how NMF has expressed the digit as a sum of the components!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Create an NMF model: model\n",
    "model = NMF(n_components=7)\n",
    "\n",
    "# Apply fit_transform to samples: features\n",
    "features = model.fit_transform(samples)\n",
    "\n",
    "# Call show_as_image on each component\n",
    "for component in model.components_:\n",
    "    show_as_image(component)\n",
    "\n",
    "# Assign the 0th row of features: digit_features\n",
    "digit_features = features[0]\n",
    "\n",
    "# Print digit_features\n",
    "print(digit_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA doesn't learn parts\n",
    "\n",
    "Unlike NMF, PCA doesn't learn the parts of things. Its components do not correspond to topics (in the case of documents) or to parts of images, when trained on images. Verify this for yourself by inspecting the components of a PCA model fit to the dataset of LED digit images from the previous exercise. The images are available as a 2D array samples. Also available is a modified version of the show_as_image() function which colors a pixel red if the value is negative.\n",
    "\n",
    "After submitting the answer, notice that the components of PCA do not represent meaningful parts of images of LED digits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a PCA instance: model\n",
    "model = PCA(n_components=7)\n",
    "\n",
    "# Apply fit_transform to samples: features\n",
    "features = model.fit_transform(samples)\n",
    "\n",
    "# Call show_as_image on each component\n",
    "for component in model.components_:\n",
    "    show_as_image(component)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building recommender systems using NMF\n",
    "\n",
    "- Finding similar articles :\n",
    "    - Recommend the articles to the customer, who has read the similar articles \n",
    "    - Similar Articles to find out from the similar topics\n",
    "\n",
    "#### Applying NMF \n",
    "#### Strategy\n",
    "- Apply NMF to the word-frequency of articles\n",
    "- NMF feature values describe the topics\n",
    "- so similar articles have similar NMF features values\n",
    "\n",
    "#### Compare the features values\n",
    "- example as shown below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# token\n",
    "nmf = NMF(n_components=6)\n",
    "\n",
    "#fit_transform()\n",
    "nmf_features = nmf.fit_transform(articles)\n",
    "\n",
    "# Compare the articles using NMF features\n",
    "\n",
    "# Version of articles\n",
    "# - different versions of the documents have a same topic proportions\n",
    "# - exact feature values may be different\n",
    "\n",
    "#E.g. Strong version of articles : Dog bites man!, Attack by terrible canine leaves man paralyzed\n",
    "#E.g. Week Version of articles : You may have heard, Unfortunately,  it seems that a dog has perhaps bitten a man\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine Similarity\n",
    "#### Use angle between lines\n",
    "- High Values means more similarity\n",
    "- Maximum value is 1, when angle is \"0˚\"\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Cosine Similarities\n",
    "\n",
    "# first import normalize function and apply to nmf_features\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# normalize\n",
    "norm_features = normalize(nmf_features)\n",
    "\n",
    "# Select the row corresponding to the current article\n",
    "current_article = norm_features[23,:]\n",
    "\n",
    "# assign the dot method to normalize all the similarities\n",
    "similarities  = norm_features.dot(current_article)\n",
    "\n",
    "# result\n",
    "print(similarities)\n",
    "\n",
    "# label with title using pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# normalize nmf_features\n",
    "\n",
    "\n",
    "# titles with similarities\n",
    "titles = pd.DataFrame(norm_features, index=titles)\n",
    "\n",
    "# now use loc method to see current article\n",
    "current_article = df.loc['Dog bites man']\n",
    "\n",
    "# print similarities using nlargest()\n",
    "print(similarities.nlargest())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which articles are similar to 'Cristiano Ronaldo'?\n",
    "\n",
    "In the video, you learned how to use NMF features and the cosine similarity to find similar articles. Apply this to your NMF model for popular Wikipedia articles, by finding the articles most similar to the article about the footballer Cristiano Ronaldo. The NMF features you obtained earlier are available as nmf_features, while titles is a list of the article titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Normalize the NMF features: norm_features\n",
    "norm_features = normalize(nmf_features)\n",
    "\n",
    "# Create a DataFrame: df\n",
    "df = pd.DataFrame(norm_features, index=titles)\n",
    "\n",
    "# Select the row corresponding to 'Cristiano Ronaldo': article\n",
    "article = df.loc['Cristiano Ronaldo']\n",
    "\n",
    "# Compute the dot products: similarities\n",
    "similarities = df.dot(article)\n",
    "\n",
    "# Display those with the largest cosine similarity\n",
    "print(similarities.nlargest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend musical artists part I\n",
    "\n",
    "In this exercise and the next, you'll use what you've learned about NMF to recommend popular music artists! You are given a sparse array artists whose rows correspond to artists and whose column correspond to users. The entries give the number of times each artist was listened to by each user.\n",
    "\n",
    "In this exercise, build a pipeline and transform the array into normalized NMF features. The first step in the pipeline, MaxAbsScaler, transforms the data so that all users have the same influence on the model, regardless of how many different artists they've listened to. In the next exercise, you'll use the resulting normalized NMF features for recommendation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import Normalizer, MaxAbsScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a MaxAbsScaler: scaler\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "# Create an NMF model: nmf\n",
    "nmf = NMF(n_components=20)\n",
    "\n",
    "# Create a Normalizer: normalizer\n",
    "normalizer = Normalizer()\n",
    "\n",
    "# Create a pipeline: pipeline\n",
    "pipeline = make_pipeline(scaler, nmf, normalizer)\n",
    "\n",
    "# Apply fit_transform to artists: norm_features\n",
    "norm_features = pipeline.fit_transform(artists)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend musical artists part II\n",
    "\n",
    "Suppose you were a big fan of Bruce Springsteen - which other musicial artists might you like? Use your NMF features from the previous exercise and the cosine similarity to find similar musical artists. A solution to the previous exercise has been run, so norm_features is an array containing the normalized NMF features as rows. The names of the musical artists are available as the list artist_names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame: df\n",
    "df = pd.DataFrame(norm_features, index=artist_names)\n",
    "\n",
    "# Select row of 'Bruce Springsteen': artist\n",
    "artist = df.loc['Bruce Springsteen']\n",
    "\n",
    "# Compute cosine similarities: similarities\n",
    "similarities = df.dot(artist)\n",
    "\n",
    "# Display those with highest cosine similarity\n",
    "print(similarities.nlargest())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
